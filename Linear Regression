'''Linear Regression (Using Logic)'''

      import numpy as np
      import pandas as pd
      import matplotlib.pyplot as plt
      plt.rcParams['figure.figsize'] = (20.0,10.0)

      # Reading Data
      data = pd.read_excel('headbrain.xlsx')
      print(data.shape)
      data.head()

      # Collecting X and Y
      X= data['Head Size'].values
      Y= data['Brain Weight'].values

      # Mean X and Y
      mean_x = np.mean(X)
      mean_y = np.mean(Y)

      # Total number of values
      n = len(X)

      # Using the formula, calculate Slope and c
      numer = 0
      denom = 0
      for i in range(n):
          numer += ((X[i] - mean_x)*(Y[i] - mean_y))
          denom += (X[i] - mean_x)**2
      m = numer/denom
      c = mean_y - (m * mean_x)

      # Print Coefficients
      print(m,c)

      # Plotting values and Regression line
      max_x = np.max(X) + 100
      min_x = np.min(X) - 100

      # Calculating line values of x and y
      x = np.linspace(min_x, max_x, 1000)
      y = m*x + c

      # Plotting Line
      plt.plot(x, y, color = '#58b970', label = 'Regression Line')
      # Plotting Scatter Points
      plt.scatter(X, Y, c = '#ef5423', label = 'Scatter Plot')

      plt.xlabel('Head Size')
      plt.ylabel('Brain Weight')
      plt.legend()
      plt.show()

      # Calculation of R2 score
      ss_t = 0
      ss_r = 0
      for i in range(n):
          y_pred = m*X[i] + c
          ss_t = (Y[i] - mean_y)**2
          ss_r = (Y[i] - y_pred)**2
      r2 = 1 - (ss_r/ss_t)
      print(r2)

''' Linear Regression (Using Scikit Learn) '''

# Example 1

      import numpy as np
      import pandas as pd
      import matplotlib.pyplot as plt
      from sklearn.linear_model import LinearRegression
      from sklearn.metrics import mean_squared_error
      plt.rcParams['figure.figsize'] = (20.0,10.0)

      # Reading Data
      data = pd.read_excel('headbrain.xlsx')
      print(data.shape)
      data.head()

      # Collecting X and Y
      X= data['Head Size'].values
      Y= data['Brain Weight'].values

      # Cannot use Rank 1 matrix in scikit learn
      X = X.reshape((237,1))

      # Creating Model
      reg = LinearRegression()
      # Fitting training Data
      reg = reg.fit(X, Y)
      # Y Prediction
      Y_pred = reg.predict(X)
      m = reg.coef_

      # Plot outputs
      plt.scatter(X, Y,  color='black')
      plt.plot(X, Y_pred, color='blue', linewidth=3)
      plt.xticks(())
      plt.yticks(())
      plt.show()

      # Calculating R2 Score
      r2_score = reg.score(X, Y)

      print(r2_score)

# Example 2

      import matplotlib.pyplot as plt
      import numpy as np
      from sklearn import datasets, linear_model
      from sklearn.metrics import mean_squared_error, r2_score

      # Load the diabetes dataset
      diabetes = datasets.load_diabetes()

      # Use only one feature
      diabetes_X = diabetes.data[:, np.newaxis, 2]

      # Split the data into training/testing sets
      diabetes_X_train = diabetes_X[:-20]
      diabetes_X_test = diabetes_X[-20:]

      # Split the targets into training/testing sets
      diabetes_y_train = diabetes.target[:-20]
      diabetes_y_test = diabetes.target[-20:]

      # Create linear regression object
      regr = linear_model.LinearRegression()

      # Train the model using the training sets
      regr.fit(diabetes_X_train, diabetes_y_train)

      # Make predictions using the testing set
      diabetes_y_pred = regr.predict(diabetes_X_test)

      # The coefficients
      print('Coefficients: \n', regr.coef_)
      # The mean squared error
      print("Mean squared error: %.2f"
            % mean_squared_error(diabetes_y_test, diabetes_y_pred))
      # Explained variance score: 1 is perfect prediction
      print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))

      # Plot outputs
      plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')
      plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)

      plt.xticks(())
      plt.yticks(())
      plt.show()
